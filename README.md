# Titanic Survival Predictions
Hey! I'm Dallas, an aspiring Data Analyst getting back into Machine Learning. I've previously taken an ML class in my colligate courses, but never did too much development on my own. What better place to start with the "Hello World" of ML: Kaggle's Titanic Survival Predictions?
There are... probably better places to start. This dataset gets used too much.

This project is aimed to predict the survival of the passengers aboard the Titanic using the given dataset of passenger information. This model uses a RandomForestClassifier to predict the survival of each passenger based on their demographic data such as age, gender, class, and more. Here's a step-by-step guide on how the model works:

# Data Cleaning and Preprocessing
The first step is to load and preprocess the given dataset by using Pandas and NumPy libraries. The dataset is loaded from two different files, train.csv and test.csv. After loading the dataset, we visualize the correlation between different attributes using a heatmap generated by the seaborn library.

Then, we use the StratifiedShuffleSplit method to create training and test sets with a 80-20 split. The method ensures that the distribution of the target variable (survived or not) is the same in both sets.

The next step is to estimate missing values. We fill the missing Age values by computing the mean age of the passengers using the SimpleImputer method. We also encode categorical features like sex and embarked using the OneHotEncoder method.

Finally, we drop some unnecessary features like name, ticket, and cabin using the FeatureDropper method.

# Model Training
We then use a pipeline to create a sequence of steps to preprocess the data before feeding it into the model. The pipeline is made up of the AgeImputer, FeatureEncoder, and FeatureDropper classes.

After preprocessing the data, we split the training data into X and Y arrays to fit the data to the RandomForestClassifier. We scale the X data using StandardScaler from sklearn.preprocessing. Then, we perform GridSearchCV to search for the best hyperparameters for the RandomForestClassifier.

# Model Evaluation
We evaluate the performance of the model using the test set. We preprocess the test data using the same pipeline and evaluate the final model's accuracy on the test data using the score method.

# Generating Predictions
Finally, we use the model to generate predictions for the passengers in the test.csv file. We preprocess the data and scale it using the pipeline and StandardScaler. Then we use the prod_final_clf model to predict the survival of each passenger in the test set. The predictions are saved in a CSV file named predictions.csv.







